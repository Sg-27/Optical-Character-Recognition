{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sg-27/Optical-Character-Recognition/blob/main/Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4gdgdiZu2BS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(f\"We are training on {device} for this experiment\")\n",
        "\n",
        "assert 'cuda' in repr(device), \"GPU is not selected in hardware accelerator dropdown\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw92CNA0vchJ",
        "outputId": "aa020ad2-1000-4556-cacb-0f6396ed82fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are training on cuda:0 for this experiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqpaQ_qkvfR-",
        "outputId": "cb7bd3e3-a257-4638-d1d1-d8a7982b901b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "your_google_drive_path = \"/content/drive/MyDrive/Custom Dataset/\"\n",
        "import os\n",
        "assert os.path.isdir(your_google_drive_path), f\"{your_google_drive_path} is not a valid location\""
      ],
      "metadata": {
        "id": "eqFz5Oc5vgCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDigitsDataset(Dataset):\n",
        "    def __init__(self, root_folder, transform=None):\n",
        "        self.root_folder = root_folder\n",
        "        self.transform = transform\n",
        "        self.data, self.labels = self.load_data()\n",
        "\n",
        "\n",
        "    def load_data(self):\n",
        "        data = []\n",
        "        labels = []\n",
        "        digit_folders = sorted(os.listdir(self.root_folder))\n",
        "\n",
        "        for label, digit_folder in enumerate(digit_folders):\n",
        "            digit_path = os.path.join(self.root_folder, digit_folder)\n",
        "            for image_name in os.listdir(digit_path):\n",
        "                image_path = os.path.join(digit_path, image_name)\n",
        "                img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
        "\n",
        "                data.append(img)\n",
        "                labels.append(label)\n",
        "                #print(label)\n",
        "\n",
        "        return data, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.data[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "yUEyvrhiwY8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Resize(size=(32,32))\n",
        "# ])\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size=(32,32)),\n",
        "    transforms.CenterCrop(size=(24,24))\n",
        "])\n",
        "batch_size=4\n",
        "\n",
        "# Specify the path to the root folder containing digit folders\n",
        "#root_folder_path = '/path/to/root_folder'\n",
        "your_google_drive_path='/content/drive/MyDrive/Custom Dataset'\n",
        "custom_dataset = CustomDigitsDataset(your_google_drive_path, transform=transform)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "print(len(custom_dataset))\n",
        "train_size = int(0.8 * len(custom_dataset))\n",
        "test_size = len(custom_dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size])\n",
        "\n",
        "# Example usage:\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RD2YrarxFQ_",
        "outputId": "efa493a4-43d3-4fd7-c7bc-76abd103a61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "YHIIpeau3XTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an imageonefinal22@gmail.com\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "print(images.shape)\n",
        "classes = ('zero', 'one', 'two', 'three',\n",
        "           'four', 'five','six','seven','eight','nine')\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "W2iLknuV3E_g",
        "outputId": "53881359-1e49-49ee-f6c1-e0e4413e5c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 24, 24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nine  four  four  seven\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import DataLoader\n",
        "# from torchvision import datasets, transforms\n",
        "\n",
        "# Define the basic block for the ResNet\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet-9 model\n",
        "class ResNet9(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet9, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.block1 = BasicBlock(64, 128, stride=2)\n",
        "        self.block2 = BasicBlock(128, 256, stride=2)\n",
        "        self.block3 = BasicBlock(256, 512, stride=2)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "QcLbsCBn9Bip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ResNet9().to(device)"
      ],
      "metadata": {
        "id": "yM9JaHx_9GEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "IDnC77mx9I6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validator(test_loader=None,model=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = model(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            # perform max along dimension 1, since dimension 0 is batch dimension\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on the 540 test images: {100 * correct // total} %')\n",
        "    return correct/total"
      ],
      "metadata": {
        "id": "FcyCTbcU9JhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch=0\n",
        "end_epoch=20"
      ],
      "metadata": {
        "id": "uZAsUJea9NDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "your_google_drive_path=\"/content/drive/MyDrive/check_point/\""
      ],
      "metadata": {
        "id": "BuiYcpSIMxPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = -1.0\n",
        "for epoch in range(start_epoch,end_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    current_accuracy = validator(test_loader=test_loader,model=model)\n",
        "    if current_accuracy>best_accuracy:\n",
        "        best_accuracy = current_accuracy\n",
        "\n",
        "        torch.save(\n",
        "            {'epoch':epoch,\n",
        "             'model_state_dict': model.state_dict(),\n",
        "             'optimizer_state_dict': optimizer.state_dict()\n",
        "             },\n",
        "\n",
        "             your_google_drive_path+'best_model.pth')\n",
        "\n",
        "    #Save model as checkpoint\n",
        "    torch.save(\n",
        "        {'epoch':epoch,\n",
        "         'model_state_dict': model.state_dict(),\n",
        "         'optimizer_state_dict': optimizer.state_dict()\n",
        "         },\n",
        "         your_google_drive_path+'checkpoint.pth')\n",
        "\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbLelbjq9Qgu",
        "outputId": "756ebe85-999a-4cdd-aa79-0994bb30cbfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 540 test images: 45 %\n",
            "Accuracy of the network on the 540 test images: 50 %\n",
            "Accuracy of the network on the 540 test images: 60 %\n",
            "Accuracy of the network on the 540 test images: 68 %\n",
            "Accuracy of the network on the 540 test images: 67 %\n",
            "Accuracy of the network on the 540 test images: 62 %\n",
            "Accuracy of the network on the 540 test images: 69 %\n",
            "Accuracy of the network on the 540 test images: 76 %\n",
            "Accuracy of the network on the 540 test images: 75 %\n",
            "Accuracy of the network on the 540 test images: 72 %\n",
            "Accuracy of the network on the 540 test images: 72 %\n",
            "Accuracy of the network on the 540 test images: 73 %\n",
            "Accuracy of the network on the 540 test images: 73 %\n",
            "Accuracy of the network on the 540 test images: 73 %\n",
            "Accuracy of the network on the 540 test images: 73 %\n",
            "Accuracy of the network on the 540 test images: 74 %\n",
            "Accuracy of the network on the 540 test images: 74 %\n",
            "Accuracy of the network on the 540 test images: 74 %\n",
            "Accuracy of the network on the 540 test images: 75 %\n",
            "Accuracy of the network on the 540 test images: 75 %\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "images, labels=next(dataiter)\n",
        "batch_size=4\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "#print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nZ5AuLU7NPvl",
        "outputId": "121b37cf-ddb0-4542-abe7-349cb17a75b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seven one   three eight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net_best = ResNet9().to(device)\n",
        "checkpoint = torch.load(your_google_drive_path+'best_model.pth')\n",
        "net_best.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = net_best(images)"
      ],
      "metadata": {
        "id": "vzq4JtkV9gLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "id": "P3WqxIcY9kjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6edbb5c3-e362-4501-ff46-f58d6ce5f436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:  seven four  three eight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UWVLG7O08iG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}